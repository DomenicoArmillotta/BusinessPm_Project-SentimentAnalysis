{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Progetto_Business&PM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **First Question:**\n",
        "\n",
        "The research will focus on the following question:\n",
        "\n",
        "**\"Can sentiment analysis technology be used in a realistic business environment to understand customer feedback left on social media?\"**\n",
        "\n",
        "Then we will analyze some textual reviews and we will label them with our rating model, and we will understand how much the rating of the classified reviews differs from the automatic system, from the rating\n",
        "of real reviews (assuming that the stars left by users are balanced\n",
        "with the textual review left).\n"
      ],
      "metadata": {
        "id": "cQOruLeMggnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "import nltk\n",
        "import re\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import sys\n",
        "import numpy\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict \n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import cross_val_predict \n",
        "from sklearn.model_selection import learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "id": "jGhiGxLlgzHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding label with the three categories\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "df = pd.read_csv('Datafiniti_Hotel_Reviewscomplete.csv')\n",
        "\n",
        "min = 0\n",
        "max = 5\n",
        "col = 'reviews.rating'\n",
        "conditions = [(df[col] >= min) & (df[col] < min+3),\n",
        "              (df[col] == min + 3) & (df[col] == min+3),\n",
        "              (df[col] > min+3)  & (df[col] <= max)]\n",
        "choices = [\"Bad\",\"Neutral\",\"Good\"]\n",
        "df[\"Evaluation\"] = np.select(conditions, choices, default=np.nan)\n",
        "\n",
        "df.to_csv('Datafiniti_Hotel_Reviewscomplete.csv', index=False)"
      ],
      "metadata": {
        "id": "x4KuxqeVg6VJ",
        "outputId": "c90c07c5-627d-4423-c669-0e793bf8afce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-2d65612bd41a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Datafiniti_Hotel_Reviewscomplete.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datafiniti_Hotel_Reviewscomplete.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SPLIT & BALANCE\n",
        "#split train and test and do the balance on the train\n",
        "#traib 75% test 25%\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample\n",
        "import seaborn as sns\n",
        "from csv import reader\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "#split the data into train and test set\n",
        "#reading dataset\n",
        "readCsv = pd.read_csv(\"Datafiniti_Hotel_Reviewscomplete.csv\")\n",
        "\n",
        "\n",
        "train,test = train_test_split(readCsv, test_size=0.25, random_state=1)\n",
        "#save the data\n",
        "train.to_csv('train.csv',index=False)\n",
        "test.to_csv('test.csv',index=False)\n",
        "\n",
        "#PLOT 1\n",
        "plt.title(\"Class of imbalanced training Set\")\n",
        "# read a tips.csv file from seaborn library\n",
        "df = pd.read_csv(\"train.csv\")\n",
        "# count plot along x axis\n",
        "sns.countplot(x=\"Evaluation\", data = df , palette=\"magma\")\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "\n",
        "#do rebalncing training set\n",
        "class_0 = train[train['Evaluation'] == \"Good\"]\n",
        "class_1 = train[train['Evaluation'] == \"Bad\"]\n",
        "class_2 = train[train['Evaluation'] == \"Neutral\"]\n",
        "class_count_0, class_count_1, class_count_2 = train['Evaluation'].value_counts()\n",
        "class_0_under = class_0.sample(class_count_1)\n",
        "test_under = pd.concat([class_0_under, class_1, class_2], axis=0)\n",
        "\n",
        "\n",
        "test_under.to_csv(\"BalancedTrain.csv\", index=None)\n",
        "BalancedTrain = pd.read_csv('BalancedTrain.csv')\n",
        "\n",
        "#PLOT2\n",
        "plt.title(\"Class of balanced training Set\")\n",
        "# read a tips.csv file from seaborn library\n",
        "df = pd.read_csv(\"BalancedTrain.csv\")\n",
        "# count plot along x axis\n",
        "sns.countplot(x=\"Evaluation\", data = df , palette=\"magma\")\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zVYPdW02g9py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TEXT RETRIVE & ELABORATION TEST & TRAIN\n",
        "#TEXT RETRIEVE and CLEANING\n",
        "#1. lower case\n",
        "#2. remove punctuation\n",
        "#3. remove mention @...\n",
        "#4 remove link http:....\n",
        "#5. remove emoji\n",
        "\n",
        "#TEXT ELABORATION\n",
        "#1. tokenization\n",
        "#2. stop word filtering\n",
        "#3. lematizzation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#reading the data\n",
        "test_csv = pd.read_csv('test.csv') \n",
        "train_csv = pd.read_csv('BalancedTrain.csv')\n",
        "\n",
        "\n",
        "train_X_non = train_csv['reviews.text'] #without preprocessing\n",
        "train_y = train_csv['Evaluation']   #only evaluation\n",
        "test_X_non = test_csv['reviews.text'] \n",
        "test_y = test_csv['Evaluation']  \n",
        "train_X_cleaned=[]\n",
        "test_X_cleaned=[]\n",
        "train_X=[] #with preprocessing\n",
        "test_X=[]\n",
        "\n",
        "\n",
        "emoji_pattern = re.compile(\"[\"\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "\n",
        "#Cleaning Train\n",
        "import re\n",
        "for i in range(0, len(train_X_non)):\n",
        "    review = train_X_non[i]\n",
        "    review = str(review).lower()\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation)) #remove puntuaction\n",
        "    review = re.sub('@[^\\s]+','',review) #remove mention\n",
        "    review = re.sub('http[^\\s]+','',review) #remove link\n",
        "    review=emoji_pattern.sub(r'', review) # remove emoji\n",
        "    train_X_cleaned.append(review)\n",
        "\n",
        "#Cleaning Test\n",
        "import re\n",
        "for i in range(0, len(test_X_non)):\n",
        "    review = test_X_non[i]\n",
        "    review = str(review).lower()\n",
        "    review = review.translate(str.maketrans('', '', string.punctuation))\n",
        "    review = re.sub('@[^\\s]+','',review) #remove mention\n",
        "    review = re.sub('http[^\\s]+','',review) #remove link\n",
        "    review=emoji_pattern.sub(r'', review) # remove emoji\n",
        "    test_X_cleaned.append(review)\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#Preprocessing Train\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()\n",
        "filtered_sent=[]\n",
        "for i in range(0, len(train_X_cleaned)):\n",
        "    review = train_X_cleaned[i]\n",
        "    review=word_tokenize(review) #tokenization\n",
        "    for w in review:             #stop word filtering\n",
        "        if w not in stop_words:\n",
        "            filtered_sent.append(w)\n",
        "    review=filtered_sent\n",
        "    filtered_sent=[]\n",
        "    for w in review:            #stemming\n",
        "        filtered_sent.append(lemmatizer.lemmatize(w))\n",
        "    review=filtered_sent\n",
        "    filtered_sent=[]\n",
        "    review = ' '.join(review)\n",
        "    train_X.append(review)\n",
        "    \n",
        "#Preprocessing Test\n",
        "stop_words=set(stopwords.words(\"english\"))\n",
        "ps = PorterStemmer()\n",
        "filtered_sent=[]\n",
        "for i in range(0, len(test_X_cleaned)):\n",
        "    review = test_X_cleaned[i]\n",
        "    review=word_tokenize(review) #tokenization\n",
        "    for w in review:             #stop word filtering\n",
        "        if w not in stop_words:\n",
        "            filtered_sent.append(w)\n",
        "    review=filtered_sent\n",
        "    filtered_sent=[]\n",
        "    for w in review:            #stemming\n",
        "        filtered_sent.append(lemmatizer.lemmatize(w))\n",
        "    review=filtered_sent\n",
        "    filtered_sent=[]\n",
        "    review = ' '.join(review) #CON QUESTA UNISCO\n",
        "    test_X.append(review)\n",
        "    "
      ],
      "metadata": {
        "id": "8kps0n6chJFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vect=CountVectorizer( max_features=5000,lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,1))\n",
        "X_train_counts=count_vect.fit_transform(raw_documents=train_X)\n",
        "\n",
        "tfidf_transformer=TfidfTransformer()\n",
        "X_train_tf=tfidf_transformer.fit_transform(X_train_counts)\n",
        "\n",
        "X_test_counts=count_vect.fit_transform(raw_documents=test_X)\n",
        "X_test_tf=tfidf_transformer.fit_transform(X_test_counts)\n",
        "\n",
        "\n",
        "feature_names = count_vect.get_feature_names()\n",
        "dense = X_train_tf.todense()\n",
        "denselist = dense.tolist()\n",
        "df2 = pd.DataFrame(denselist, columns=feature_names)\n",
        "print(df2)"
      ],
      "metadata": {
        "id": "c0FTjMenhwgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#serve a trasformare le label in numeri\n",
        "import copy\n",
        "train_y_clf = copy.deepcopy(train_y)\n",
        "test_y_clf = copy.deepcopy(test_y)\n",
        "\n",
        "df_train_y=train_y\n",
        "for i  in range(0, len(df_train_y)):\n",
        "    if df_train_y[i]==\"Good\":\n",
        "        df_train_y[i]=2\n",
        "    elif df_train_y[i]==\"Neutral\":\n",
        "        df_train_y[i]=1\n",
        "    else :\n",
        "        df_train_y[i]=-1\n",
        "\n",
        "df_test_y = test_y\n",
        "for i  in range(0, len(df_test_y)):\n",
        "    if df_test_y[i]==\"Good\":\n",
        "        df_test_y[i]=2\n",
        "    elif df_test_y[i]==\"Neutral\":\n",
        "        df_test_y[i]=1\n",
        "    else :\n",
        "        df_test_y[i]=-1\n",
        "        \n",
        "df_train_y.to_csv('LabelToNumber-train.csv', index=None)\n",
        "df_test_y.to_csv('LabelToNumber-test.csv')\n",
        "\n",
        "df_train_y = pd.read_csv('LabelToNumber-train.csv')\n",
        "df_test_y = pd.read_csv('LabelToNumber-test.csv')"
      ],
      "metadata": {
        "id": "-yW_eBMch5nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#KNN \n",
        "knn = KNeighborsClassifier(n_neighbors=200,weights='uniform',algorithm='auto', n_jobs=-1)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(knn, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(knn,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(knn,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(knn,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(knn,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(knn,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(knn,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "\n",
        "\n",
        "\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a KNN model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zbzfcjAlh9SR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#MULTINOMIAL DB\n",
        "naive_bayes_classifier = MultinomialNB(alpha=0.5)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(naive_bayes_classifier, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(naive_bayes_classifier,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(naive_bayes_classifier,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(naive_bayes_classifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(naive_bayes_classifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(naive_bayes_classifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(naive_bayes_classifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a Multinomial NB model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-BuC-SF6iALy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BAGGING\n",
        "bgclassifier = BaggingClassifier(base_estimator=None, n_estimators=30, bootstrap_features=False, oob_score=False, n_jobs=-1)\n",
        "\n",
        "accuracy = cross_val_score(bgclassifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(bgclassifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(bgclassifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(bgclassifier,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a BAGGING model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TfOa4RdviFbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DECISION TREE\n",
        "decison_gini = DecisionTreeClassifier(max_depth=12,criterion='entropy')\n",
        "train_sizes, train_scores, valid_scores = learning_curve(decison_gini, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(decison_gini,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(decison_gini,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(decison_gini,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(decison_gini,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(decison_gini,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(decison_gini,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a DECISION TREE model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "plEAQGSfiGdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ADA BOOST\n",
        "ada = AdaBoostClassifier(n_estimators=150,learning_rate=1)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(ada, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(ada,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(ada,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(ada,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(ada,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(ada,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(ada,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a ADA BOOST model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K8NtU1mhiJ1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVM\n",
        "clf = svm.SVC(kernel='poly' ,degree=3,cache_size=500)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(clf, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(clf,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(clf,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(clf,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(clf,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(clf,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(clf,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a SVM model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QQQSSbH2iNZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RANDOM FOREST\n",
        "forest = RandomForestClassifier(n_estimators=60,max_depth=8, criterion='gini',max_features='auto',bootstrap=False, n_jobs=-1)\n",
        "train_sizes, train_scores, valid_scores = learning_curve(forest, X_train_tf, np.ravel(df_train_y.astype(int)),cv=10)\n",
        "y_pred = cross_val_predict(forest,X_train_tf,  np.ravel(df_train_y.astype(int)), cv=10)\n",
        "results = cross_validate(forest,X_train_tf, np.ravel(df_train_y.astype(int)),cv=10,scoring='neg_mean_squared_error')\n",
        "\n",
        "accuracy = cross_val_score(forest,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='accuracy') \n",
        "precision = cross_val_score(forest,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='precision_macro')\n",
        "recall = cross_val_score(forest,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='recall_macro') \n",
        "f1 = cross_val_score(forest,X_train_tf,np.ravel(df_train_y.astype(int)), cv=10, scoring='f1_macro') \n",
        "\n",
        "\n",
        "print(\"\\nAccuracy: \", accuracy) \n",
        "acc_round = numpy.round(accuracy.mean(),2)\n",
        "print(\"\\nAccuracy mean: \", acc_round)\n",
        "print(\"\\nPrecision: \", precision)\n",
        "prec_round = numpy.round(precision.mean(),2)\n",
        "print(\"\\nPrecision mean: \", prec_round)\n",
        "print(\"\\nRecall: \", recall)\n",
        "rec_round = numpy.round(recall.mean(),2)\n",
        "print(\"\\nRecall mean: \", rec_round)\n",
        "print(\"\\nF1: \", f1)\n",
        "f1_round = numpy.round(f1.mean(),2)\n",
        "print(\"\\nF1 mean: \", f1_round)\n",
        "\n",
        "\n",
        "print('Training scores:\\n\\n', train_scores)\n",
        "print('\\n', '-' * 70) # separator to make the output easy to read\n",
        "print('\\nValidation scores:\\n\\n', valid_scores)\n",
        "\n",
        "train_scores_mean = train_scores.mean(axis = 1)\n",
        "validation_scores_mean = valid_scores.mean(axis = 1)\n",
        "print('Mean training scores\\n\\n', pd.Series(train_scores_mean, index = train_sizes))\n",
        "print('\\n', '-' * 20) # separator\n",
        "print('\\nMean validation scores\\n\\n',pd.Series(validation_scores_mean, index = train_sizes))\n",
        "print('\\n\\n\\n')\n",
        "#print (resultstot)\n",
        "plt.style.use('seaborn')\n",
        "plt.plot(train_sizes, train_scores_mean, label = 'Training accuracy')\n",
        "plt.plot(train_sizes, validation_scores_mean, label = 'Validation accuracy')\n",
        "plt.ylabel('Accuracy', fontsize = 14)\n",
        "plt.xlabel('Training set size', fontsize = 14)\n",
        "plt.title('Learning curves for a RANDOM FOREST model', fontsize = 18, y = 1.03)\n",
        "plt.legend()\n",
        "plt.ylim(0,1.25)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iU5Ri8tMiPtt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#T TEST FOR THE TWO BEST CLASSIFIER\n",
        "from mlxtend.evaluate import paired_ttest_kfold_cv\n",
        "\n",
        "t, p = paired_ttest_kfold_cv(estimator1=clf,\n",
        "                             estimator2=bgclassifier,\n",
        "                             X=X_train_tf,\n",
        "                             y=np.ravel(df_train_y.astype(int)), \n",
        "                             random_seed=1)\n",
        "\n",
        "print('p value: %.6f' % p)"
      ],
      "metadata": {
        "id": "rpTUD9bsiR6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#PLOT THE DIFFERENCE BETWEEN N-GRAM FOR THE BEST CLASSIFICATOR \n",
        "i=1\n",
        "acc = 'n-grams = '\n",
        "df = pd.DataFrame()\n",
        "while i<=5:\n",
        "    #TF-IDF\n",
        "    from sklearn.feature_extraction.text import TfidfTransformer\n",
        "    from sklearn.feature_extraction.text import CountVectorizer\n",
        "    tf_idf = TfidfVectorizer(max_features=5000, lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,i))\n",
        "    #applying tf idf to training data\n",
        "    X_train_tf = tf_idf.fit_transform(train_X)   #perche fit e trasform sul train e non sul test\n",
        "    #applying tf idf to training data\n",
        "    X_train_tf = tf_idf.transform(train_X)\n",
        "    #transforming test data into tf-idf matrix\n",
        "    X_test_tf = tf_idf.transform(test_X)\n",
        "    \n",
        "    names =[\"Bagging + TFIDF\"]\n",
        "    bgclassifier = BaggingClassifier(base_estimator=None, n_estimators=30, bootstrap_features=False, oob_score=False, n_jobs=-1)\n",
        "\n",
        "    classifiers = [\n",
        "        bgclassifier\n",
        "    ]\n",
        "    #iterate on classifiers\n",
        "    scores=[]\n",
        "    for name, clfs in zip(names,classifiers):\n",
        "        clfs.fit(X_train_tf, train_y_clf)\n",
        "        score= clfs.score(X_test_tf,test_y_clf)\n",
        "        scores.append(score)\n",
        "\n",
        "\n",
        "   \n",
        "    df['Classifier_Name'] = names\n",
        "    newColumn=acc +str(i)\n",
        "    df[newColumn] = scores\n",
        "    i=i+1\n",
        "\n",
        "\n",
        "    #sns.set(style=\"whitegrid\")\n",
        "    #ax = sns.barplot(x=\"Accuracy score\", y=\"Classifier_Name\", data=df)\n",
        "    #plt.show()\n",
        "\n",
        "#print(df)\n",
        "sns.color_palette(\"mako\")\n",
        "dfm = df.melt('Classifier_Name', var_name='cols', value_name='vals')\n",
        "#print(dfm)\n",
        "g = sns.catplot(x=\"cols\", y=\"vals\", hue='Classifier_Name', data=dfm, kind='point' , palette=sns.color_palette(['green', 'blue','red','yellow','purple','black']))\n",
        "g.fig.set_size_inches(15,5)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "roXwdVxSiWBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#optimized TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "tf_idf = TfidfVectorizer(max_features=5000, lowercase=True, analyzer='word', stop_words= 'english',ngram_range=(1,2))\n",
        "#applying tf idf to training data\n",
        "X_train_tf = tf_idf.fit_transform(train_X)  #perche fit e trasform sul train e non sul test\n",
        "#applying tf idf to training data\n",
        "X_train_tf = tf_idf.transform(train_X)\n",
        "\n",
        "#transforming test data into tf-idf matrix\n",
        "X_test_tf = tf_idf.transform(test_X)\n",
        "\n",
        "feature_names = tf_idf.get_feature_names()\n",
        "dense = X_train_tf.todense()\n",
        "denselist = dense.tolist()\n",
        "df2 = pd.DataFrame(denselist, columns=feature_names)"
      ],
      "metadata": {
        "id": "6PSTwdKWiYm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#bagging CLASSIFIER\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix,zero_one_loss\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix,zero_one_loss\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn import datasets\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from time import process_time\n",
        "bgclassifier = BaggingClassifier(base_estimator=None, n_estimators=30, bootstrap_features=False, oob_score=False, n_jobs=-1)\n",
        "\n",
        "bgclassifier.fit(X_train_tf, train_y_clf) #faccio il train con le recensioni + l'evaluation\n",
        "y_pred = bgclassifier.predict(X_test_tf) #faccio la predizione delle recensioni test \n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "class_names = ['Bad', 'Neutral','Good']\n",
        "\n",
        "matrix = metrics.confusion_matrix(test_y_clf, y_pred)\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.heatmap(matrix,\n",
        "                cmap=sns.diverging_palette(150, 275, s=80, l=55, n=9),\n",
        "                xticklabels=[\"Bad\",\"Neutral\",\"Good\"],\n",
        "                yticklabels=[\"Bad\",\"Neutral\",\"Good\"],\n",
        "                annot=True,\n",
        "                fmt='d')\n",
        "plt.title(\"Confusion matrix, without normalization -- MULTINOMIAL DB\")\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()\n",
        "\n",
        "results = confusion_matrix(test_y_clf, y_pred)\n",
        "error = zero_one_loss(test_y_clf, y_pred)\n",
        "lerror = round(error,2)\n",
        "\n",
        "FP = results.sum(axis=0) - numpy.diag(results)\n",
        "FN = results.sum(axis=1) - numpy.diag(results)\n",
        "TP = numpy.diag(results)\n",
        "TN = results.sum() - (FP + FN + TP)\n",
        "prec = TP / TP + FP\n",
        "sens = TP / prec\n",
        "lsens = numpy.round(sens,2)\n",
        "\n",
        "TPR = TP/(TP+FN)\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "FPR = FP/(FP+TN)\n",
        "# False negative rate\n",
        "FNR = FN/(TP+FN)\n",
        "\n",
        "print('\\n Time Processing: \\n', process_time())\n",
        "print('\\n Zero-one classification loss: \\n', lerror)\n",
        "print('\\n True Positive: \\n', TP)\n",
        "print('\\n True Negative: \\n', TN)\n",
        "print('\\n False Positive: \\n', FP)\n",
        "print('\\n False Negative: \\n', FN)\n",
        "print('\\n Sensitivity: \\n', lsens)\n",
        "print('\\n True Postive Rate: \\n', TPR)\n",
        "print('\\n True Negative Rate: \\n', TNR)\n",
        "print('\\n False Postive Rate: \\n', FPR)\n",
        "print('\\n False Negative Rate: \\n', FNR)\n",
        "\n",
        "# Specificity or true negative rate\n",
        "TNR = TN/(TN+FP)\n",
        "\n",
        "print('\\n The Classification report:\\n', classification_report(test_y_clf, y_pred, digits=2))\n",
        "accuracy = accuracy_score(test_y_clf, y_pred)\n",
        "laccuracy = numpy.round(accuracy,2)\n",
        "print('Accuracy:', laccuracy)"
      ],
      "metadata": {
        "id": "RG7_MlJdiuLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def graphHotel(textName,hotelNumber):\n",
        "    filtered_sent=[]\n",
        "    #SELECT HOTEL TO SHOW (Galleria Park Hotel)\n",
        "\n",
        "    df = pd.read_csv(\"test.csv\")\n",
        "\n",
        "    nameHotel=textName\n",
        "    #creo un dataframe con le informazioni\n",
        "    dfHotel = df.loc[df['name'] == nameHotel]\n",
        "    dfapp=dfHotel[[\"reviews.text\",\"name\" ,\"reviews.date\",\"Evaluation\"]]\n",
        "    dfapp[\"class\"] = \"\"\n",
        "    dfapp[\"valueC\"] = \"\"\n",
        "    dfapp[\"valueR\"] = \"\"\n",
        "\n",
        "    #processing delle review\n",
        "    for index, row in dfapp.iterrows():\n",
        "        review=row[\"reviews.text\"]\n",
        "        test2=[]\n",
        "        #cleaning\n",
        "        review = review.lower()\n",
        "        review = review.translate(str.maketrans('', '', string.punctuation)) #remove puntuaction\n",
        "        review = re.sub('@[^\\s]+','',review) #remove mention\n",
        "        review = re.sub('http[^\\s]+','',review) #remove link\n",
        "        review=emoji_pattern.sub(r'', review) # remove emoji\n",
        "\n",
        "        #processing\n",
        "        review=word_tokenize(review) #tokenization\n",
        "        for w in review:             #stop word filtering\n",
        "            if w not in stop_words:\n",
        "                filtered_sent.append(w)\n",
        "        review=filtered_sent\n",
        "        filtered_sent=[]\n",
        "        for w in review:            #stemming\n",
        "            filtered_sent.append(lemmatizer.lemmatize(w))\n",
        "        review=filtered_sent\n",
        "        filtered_sent=[]\n",
        "        review = ' '.join(review)\n",
        "        test2.append(review)\n",
        "        X_test_tf = tf_idf.transform(test2)\n",
        "        #do the prediction\n",
        "        MNB = bgclassifier.predict(X_test_tf)[0]\n",
        "        row[\"class\"]=MNB\n",
        "\n",
        "    #convert format of the date\n",
        "    import datetime\n",
        "    new_format = \"%Y-%m-%d\"\n",
        "    for index, row in dfapp.iterrows():\n",
        "        d1 = datetime.datetime.strptime(row[\"reviews.date\"],\"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
        "        row[\"reviews.date\"]=d1.strftime(new_format)\n",
        "\n",
        "    for index, row in dfapp.iterrows():\n",
        "        if(row[\"class\"]==\"Good\"):\n",
        "            row[\"valueC\"]=1\n",
        "        if(row[\"class\"]==\"Neutral\"):\n",
        "            row[\"valueC\"]=0\n",
        "        if(row[\"class\"]==\"Bad\"):\n",
        "            row[\"valueC\"]=-1\n",
        "\n",
        "    for index, row in dfapp.iterrows():\n",
        "        if(row[\"Evaluation\"]==\"Good\"):\n",
        "            row[\"valueR\"]=1\n",
        "        if(row[\"Evaluation\"]==\"Neutral\"):\n",
        "            row[\"valueR\"]=0\n",
        "        if(row[\"Evaluation\"]==\"Bad\"):\n",
        "            row[\"valueR\"]=-1 \n",
        "\n",
        "    YearwiseR=dfapp.groupby('reviews.date', as_index=False)['valueR'].sum()\n",
        "    YearwiseC =dfapp.groupby('reviews.date', as_index=False)['valueC'].sum()\n",
        "\n",
        "    ax = YearwiseR.plot(linewidth=5, label=\"Review retrieved\", color=\"blue\")\n",
        "    YearwiseC.plot (linewidth=3, linestyle='dashed', ax=ax, label=\"Review classified\", color=\"orange\")\n",
        "    plt.legend(loc=\"upper left\")\n",
        "    plt.title(\"Combined Statistics on Reviews of \" + nameHotel)\n",
        "    plt.xlabel(\"# of Reviews\")\n",
        "    plt.ylabel(\"Classified as\")\n",
        "    plt.savefig('Hotel1.png')\n",
        "    plt.show()\n",
        "\n",
        "    #plot dell'andamento\n",
        "    Yearwise=dfapp.groupby(by=('reviews.date')).sum()['valueC']\n",
        "    plt.figure(figsize=(8,6))\n",
        "    Yearwise.plot(linewidth=5, label=\"Review retrieved\", color=\"red\" , marker=\"+\" , mec=\"blue\" )\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.xlabel(\"Date of the review\")\n",
        "    plt.ylabel(\"Sum of vote\")\n",
        "    namePng='Hotel'+hotelNumber+'.png'\n",
        "    plt.savefig(namePng)\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UpAWewNWicm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECT HOTEL TO SHOW (Galleria Park Hotel)\n",
        "nameHotel=\"The Whitney Hotel\"\n",
        "graphHotel(nameHotel,'1')"
      ],
      "metadata": {
        "id": "kTQZCWgJig-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECT HOTEL TO SHOW (Hotel rex)\n",
        "nameHotel=\"Hotel Rex San Francisco\"\n",
        "graphHotel(nameHotel,'2')"
      ],
      "metadata": {
        "id": "P5IeuWcGi1Mo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SELECT HOTEL TO SHOW (Orlando)\n",
        "nameHotel=\"Orlando Continental Plaza Hotel\"\n",
        "graphHotel(nameHotel,'3')"
      ],
      "metadata": {
        "id": "nx3dmQSJi1pQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Second Question:**\n",
        "The second research focuses on the following question:\n",
        "\n",
        "**“Which are the main topics of the sentiment analysis application in the management field?”**\n",
        "\n",
        "A company must always keep in touch and grow along with the evolution of technology. We focused our attention in the detection of which are the main uses and possibilities of the application of the sentiment analysis through the analysis,conducted by using Natural Language Processing techniques, of papers taken from MIT Sloan school related to the management and business field.\n"
      ],
      "metadata": {
        "id": "Tly4tmX2f7b_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VFS69Je7G6o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "8bf5c172-4219-4c4d-f099-df12e3c103c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-0121877611c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mst\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mt\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\Rauro\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business and project management\\\\DataCSV\\\\'"
          ]
        }
      ],
      "source": [
        "#Topic Finder for all documents\n",
        "#Imports\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('wordnet') \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from scipy.sparse import coo_matrix\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "#ITERATION OVER FILES IN A DIRECTORY\n",
        "keyword_list = ['data mining', 'text mining', 'text analysis','sentiment analysis']\n",
        "# import required module\n",
        "import os\n",
        "# assign directory\n",
        "directory = 'C:\\\\Users\\\\Rauro\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business and project management\\\\DataCSV\\\\'\n",
        "# iterate over files in\n",
        "# that directory\n",
        "list_text=[]\n",
        "c=0\n",
        "t=0\n",
        "st=\"\"\n",
        "for filename in os.listdir(directory):\n",
        "    t+=1\n",
        "    print(t)\n",
        "    print(filename)\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    file=pd.read_csv(f,delimiter=',')\n",
        "    for i in file.index:\n",
        "        print(\"checking file\")\n",
        "        if (any(word in file[\"text\"][i] for word in keyword_list )):\n",
        "    #if(file[\"text\"][i],contains(any(keyword_list))):\n",
        "            c=c+1\n",
        "            print(\"yes\")\n",
        "            st+=file[\"text\"][i]\n",
        "print(\"checking words\")\n",
        "print(\"files found:\")\n",
        "print(c)\n",
        "if(c==0):\n",
        "    print(\"No file found\")\n",
        "    quit()\n",
        "\n",
        "result={'text':[0]}\n",
        "\n",
        "df = pd.DataFrame(data=result)\n",
        "df['text']=st\n",
        "print(df['text'])\n",
        "\n",
        "\n",
        "\n",
        "df[\"word_count\"]=df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
        "l=df[\"word_count\"][0]\n",
        "\n",
        "print(df[['text','word_count']].head())\n",
        "\n",
        "\n",
        "df.word_count.describe()\n",
        "\n",
        "\n",
        "#Identify the uncommon words\n",
        "\n",
        "freq1= pd.Series(' '.join(df['text']).split()).value_counts()[-20:]\n",
        "freq1\n",
        "\n",
        "\n",
        "#Text Pre-Processing\n",
        "\n",
        "#Removing stopwords\n",
        "stop_words= set(stopwords.words(\"english\"))\n",
        "new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
        "stop_words = stop_words.union(new_words)\n",
        "\n",
        "\n",
        "\n",
        "#Remove Punctuations\n",
        "corpus=[]\n",
        "for i in range(0, 1):\n",
        "    print(i,\"%\")\n",
        "    #Remove punctuations\n",
        "    text= re.sub('[^a-zA-Z]', ' ', df['text'][0])\n",
        "    #Convert to lower Case\n",
        "    text=text.lower()\n",
        "    #Remove tags\n",
        "    text=re.sub('\"\"',\"\",text)\n",
        "    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "    #Remove special characters and digits\n",
        "    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "    #Removing links\n",
        "    text=re.sub('https:\\/\\/.*|http:\\/\\/.*|http.*',' ',text)\n",
        "    #Convert to list from string\n",
        "    text = text.split()\n",
        "    #Stemming\n",
        "    ps=PorterStemmer()\n",
        "    #Lemmatisation\n",
        "    lem= WordNetLemmatizer()\n",
        "    text= [lem.lemmatize(word) for word in text if not word in stop_words]\n",
        "    text= \" \".join(text)\n",
        "    corpus.append(text)\n",
        "print(len(corpus))\n",
        "l=(len(corpus[0]))\n",
        "\n",
        "\n",
        "\n",
        "#Word cloud\n",
        "from os import path\n",
        "from PIL import Image\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "wordcloud = WordCloud(\n",
        "                          background_color='white',\n",
        "                          stopwords=stop_words,\n",
        "                          max_words=100,\n",
        "                          max_font_size=50, \n",
        "                          random_state=42\n",
        "                         ).generate(str(corpus[0]))\n",
        "print(wordcloud)\n",
        "fig = plt.figure(1)\n",
        "plt.imshow(wordcloud)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "fig.savefig(\"word1.png\", dpi=900)\n",
        "\n",
        "\n",
        "\n",
        "cv= CountVectorizer(stop_words=stop_words,ngram_range=(1,3))\n",
        "X=cv.fit_transform(corpus)\n",
        "list(cv.vocabulary_.keys())[:10]\n",
        "\n",
        "\n",
        "\n",
        "#Most frequently occuring words\n",
        "def get_top_n_words(corpus,n=None):\n",
        "    vec= CountVectorizer().fit(corpus)\n",
        "    bag_of_words=vec.transform(corpus)\n",
        "    sum_words= bag_of_words.sum(axis=0)\n",
        "    words_freq=[(word,sum_words[0,idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq= sorted(words_freq,key=lambda x: x[1],reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "\n",
        "\n",
        "#Convert most freq words to dataframe for plotting bar plot\n",
        "top_words=get_top_n_words(corpus,n=20)\n",
        "top_df= pd.DataFrame(top_words)\n",
        "top_df.columns=[\"Word\",\"Frequency\"]\n",
        "\n",
        "\n",
        "\n",
        "#Barplot of most freq words\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(13,8)})\n",
        "g = sns.barplot(x=\"Word\", y=\"Frequency\", data=top_df)\n",
        "g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
        "\n",
        "\n",
        "\n",
        "#Most frequently occuring Bi-grams\n",
        "def get_top_n2_words(corpus,n=None):\n",
        "    vec1= CountVectorizer(ngram_range=(2,2), max_features=2000).fit(corpus)\n",
        "    bag_of_words=vec1.transform(corpus)\n",
        "    sum_words= bag_of_words.sum(axis=0)\n",
        "    words_freq=[(word,sum_words[0,idx])for word,idx in vec1.vocabulary_.items()]\n",
        "    words_freq=sorted(words_freq,key=lambda x:x[1], reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "\n",
        "\n",
        "#Bigram Plot\n",
        "top2_words=get_top_n2_words(corpus,n=20)\n",
        "top2_df=pd.DataFrame(top2_words)\n",
        "top2_df.columns=[\"Bi-gram\",\"Freq\"]\n",
        "print(top2_df)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(13,8)})\n",
        "h=sns.barplot(x=\"Bi-gram\", y=\"Freq\", data=top2_df)\n",
        "h.set_xticklabels(h.get_xticklabels(), rotation=45)\n",
        "\n",
        "\n",
        "\n",
        "#Tri-Grams\n",
        "def get_top_n3_words(corpus,n=None):\n",
        "    vec1=CountVectorizer(ngram_range=(3,3),max_features=2000).fit(corpus)\n",
        "    bag_of_words=vec1.transform(corpus)\n",
        "    sum_words= bag_of_words.sum(axis=0)\n",
        "    words_freq=[(word,sum_words[0,idx]) for word, idx in vec1.vocabulary_.items()]\n",
        "    words_freq=sorted(words_freq,key=lambda x:x[1],reverse=True)\n",
        "    return words_freq[:n]\n",
        "\n",
        "\n",
        "\n",
        "top3_words= get_top_n3_words(corpus, n=20)\n",
        "top3_df=pd.DataFrame(top3_words)\n",
        "top3_df.columns=[\"Tri-gram\",\"Freq\"]\n",
        "print(top3_df)\n",
        "\n",
        "sns.set(rc={'figure.figsize':(13,8)})\n",
        "j=sns.barplot(x=\"Tri-gram\",y=\"Freq\",data=top3_df)\n",
        "j.set_xticklabels(j.get_xticklabels(),rotation=45)\n",
        "\n",
        "\n",
        "\n",
        "#Implementation of TF-IDF\n",
        "tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "tfidf_transformer.fit(X)\n",
        "#get feature names\n",
        "feature_names=cv.get_feature_names_out()\n",
        "\n",
        "\n",
        "\n",
        "#Ordino i risultati di tf-idf in base al punteggio\n",
        "def sort_coo(coo_matrix):\n",
        "    tuples= zip(coo_matrix.col, coo_matrix.data)\n",
        "    return sorted(tuples,key=lambda x: (x[1],x[0]), reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "def extract_topn_from_vector(feature_names,sorted_items,topn=10):\n",
        "    \"get the feature names and tf-idf score of top n items\"\n",
        "    sorted_items= sorted_items[:topn]\n",
        "    score_vals=[]\n",
        "    feature_vals=[]\n",
        "    #Index name and results\n",
        "    for idx,score in sorted_items:\n",
        "        score_vals.append(round(score,3))\n",
        "        feature_vals.append(feature_names[idx])\n",
        "        results={}\n",
        "        for idx in range(len(feature_vals)):\n",
        "            results[feature_vals[idx]]=score_vals[idx]\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #genera tf-idf per il documento\n",
        "    tf_idf_vector=tfidf_transformer.transform(cv.transform(corpus))\n",
        "    sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "    #top n=10 items da restituire\n",
        "    keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "\n",
        "    print(\"\\nKeywords:\")\n",
        "    for k in keywords:\n",
        "        print(k,keywords[k])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Topic Finder for each single document\n",
        "\n",
        "#Imports\n",
        "import os\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "nltk.download('wordnet') \n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from scipy.sparse import coo_matrix\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "#ITERATION OVER FILES IN A DIRECTORY\n",
        "keyword_list = ['data mining', 'text mining', 'text analysis','sentiment analysis']\n",
        "# import required module\n",
        "import os\n",
        "# assign directory\n",
        "directory = 'C:\\\\Users\\\\Rauro\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business and project management\\\\DataCSV\\\\'\n",
        "# iterate over files in\n",
        "# that directory\n",
        "list_text=[]\n",
        "c=0\n",
        "t=0\n",
        "st=\"\"\n",
        "for filename in os.listdir(directory):\n",
        "    t+=1\n",
        "    print(t)\n",
        "    print(filename)\n",
        "    f = os.path.join(directory, filename)\n",
        "    # checking if it is a file\n",
        "    file=pd.read_csv(f,delimiter=',')\n",
        "    for i in file.index:\n",
        "        print(\"checking file\")\n",
        "        if (any(word in file[\"text\"][i] for word in keyword_list )):\n",
        "            try:\n",
        "    #If the file contains the requested words then it creates a new folder in which will be putted all the npl results\n",
        "              #  dir=os.path.join(\"C:/Users/Rauro/OneDrive/Desktop/Uni/Business and project management/DataCSV/Results/\" ,str(file[\"year\"])) \n",
        "                dir='C:\\\\Users\\\\Rauro\\\\OneDrive\\\\Desktop\\\\Uni\\\\Business and project management\\\\Results\\\\'\n",
        "                dir=dir+str(file['year'][i])\n",
        "                print(\"DIRECTORY NAME: \")\n",
        "                print(dir)\n",
        "                print(str(file['year']))\n",
        "                if not os.path.exists(dir):\n",
        "                    os.mkdir(dir)\n",
        "                dir=dir+'\\\\'\n",
        "                c=c+1\n",
        "                print(\"yes\")\n",
        "                st+=file[\"text\"][i]\n",
        "                result={'text':[0]}\n",
        "                df = pd.DataFrame(data=result)\n",
        "                df['text']=st\n",
        "                print(file[\"year\"][i]+\" \"+file[\"title\"][i])\n",
        "                #FROM HERE I WILL BE PASTING THE WHOLE PROCESS IN ORDER TO DO IT INSIDE A SINGLE IF\n",
        "                print(\"FILE CREATION\")\n",
        "                print(\"Actual dir: \"+dir+\"\\n\")\n",
        "                \n",
        "                #CREAZIONE FILE TXT\n",
        "                save_path = dir\n",
        "                name_of_file = (file[\"title\"][i])\n",
        "                completeName = os.path.join(save_path, name_of_file+\".txt\")         \n",
        "                fileresults = open(completeName, \"a+\")\n",
        "                \n",
        "                name_of_file2 = (file[\"title\"][i]+\"text\")\n",
        "                completeName = os.path.join(save_path, name_of_file2+\".txt\")         \n",
        "                fileresults2 = open(completeName, \"a+\")\n",
        "                print(completeName)\n",
        "                \n",
        "                print(\"STARTING WORD COUNT\")\n",
        "                \n",
        "             \n",
        "                #Text Pre-Processing\n",
        "                print(\"STARTING PRE PROCESSING\")\n",
        "                \n",
        "                #Removing stopwords\n",
        "                stop_words= set(stopwords.words(\"english\"))\n",
        "                new_words = [\"using\", \"show\", \"result\", \"large\", \"also\", \"iv\", \"one\", \"two\", \"new\", \"previously\", \"shown\"]\n",
        "                stop_words = stop_words.union(new_words)\n",
        "                #Remove Punctuations\n",
        "                corpus=[]\n",
        "                for i in range(0, 1):\n",
        "                    print(i,\"%\")\n",
        "                    #Remove punctuations\n",
        "                    text= re.sub('[^a-zA-Z]', ' ', df['text'][0])\n",
        "                    #Convert to lower Case\n",
        "                    text=text.lower()\n",
        "                    #Remove tags\n",
        "                    text=re.sub('\"\"',\"\",text)\n",
        "                    text=re.sub(\"&lt;/?.*?&gt;\",\" &lt;&gt; \",text)\n",
        "                    #Remove special characters and digits\n",
        "                    text=re.sub(\"(\\\\d|\\\\W)+\",\" \",text)\n",
        "                    #Removing links\n",
        "                    text=re.sub('https:\\/\\/.*|http:\\/\\/.*|http.*',' ',text)\n",
        "                    #Convert to list from string\n",
        "                    text = text.split()\n",
        "                    #Stemming\n",
        "                    ps=PorterStemmer()\n",
        "                    #Lemmatisation\n",
        "                    lem= WordNetLemmatizer()\n",
        "                    text= [lem.lemmatize(word) for word in text if not word in stop_words]\n",
        "                    text= \" \".join(text)\n",
        "                    corpus.append(text)\n",
        "                    #fileresults.write(\"PRE PROCESSED TEXT \\n\\n\")\n",
        "                    #fileresults.write(text)\n",
        "                    #fileresults.write('\\n\\n\\n')\n",
        "                print(len(corpus))\n",
        "                l=(len(corpus[0]))\n",
        "                fileresults2.write(corpus[0])\n",
        "\n",
        "                print(\"WORD CLOUD\")\n",
        "                #Word cloud\n",
        "                from os import path\n",
        "                from PIL import Image\n",
        "                from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "                import matplotlib.pyplot as plt\n",
        "                get_ipython().run_line_magic('matplotlib', 'inline')\n",
        "                wordcloud = WordCloud(\n",
        "                                          background_color='white',\n",
        "                                          stopwords=stop_words,\n",
        "                                          max_words=100,\n",
        "                                          max_font_size=50, \n",
        "                                          random_state=42\n",
        "                                         ).generate(str(corpus[0]))\n",
        "                print(wordcloud)\n",
        "                fig = plt.figure(1)\n",
        "                plt.imshow(wordcloud)\n",
        "                plt.axis('off')\n",
        "                plt.show()\n",
        "                fig.savefig(dir+\"word1.png\", dpi=900)\n",
        "                \n",
        "                print(\"WCOUNT VECT\")\n",
        "                #Count Vectorizer\n",
        "                cv= CountVectorizer(stop_words=stop_words,ngram_range=(1,3))\n",
        "                X=cv.fit_transform(corpus)\n",
        "                list(cv.vocabulary_.keys())[:10]\n",
        "                \n",
        "                #Most frequently occuring words\n",
        "                def get_top_n_words(corpus,n=None):\n",
        "                    vec= CountVectorizer().fit(corpus)\n",
        "                    bag_of_words=vec.transform(corpus)\n",
        "                    sum_words= bag_of_words.sum(axis=0)\n",
        "                    words_freq=[(word,sum_words[0,idx]) for word, idx in vec.vocabulary_.items()]\n",
        "                    words_freq= sorted(words_freq,key=lambda x: x[1],reverse=True)\n",
        "                    return words_freq[:n]\n",
        "                print(\"STARTING UNI GRAMS\")\n",
        "               \n",
        "                #Convert most freq words to dataframe for plotting bar plot\n",
        "                top_words=get_top_n_words(corpus,n=20)\n",
        "                top_df= pd.DataFrame(top_words)\n",
        "                top_df.columns=[\"Word\",\"Frequency\"]\n",
        "                #Barplot of most freq words\n",
        "                import seaborn as sns\n",
        "                sns.set(rc={'figure.figsize':(15,12)})\n",
        "                g = sns.barplot(x=\"Word\", y=\"Frequency\", data=top_df)\n",
        "                g.set_xticklabels(g.get_xticklabels(), rotation=30)\n",
        "\n",
        "                g.figure.savefig(dir+\"unigram.png\",dpi=1000)\n",
        "                \n",
        "                print(\"STARTING bi GRAMS\")\n",
        "\n",
        "                #Most frequently occuring Bi-grams\n",
        "                def get_top_n2_words(corpus,n=None):\n",
        "                    vec1= CountVectorizer(ngram_range=(2,2), max_features=2000).fit(corpus)\n",
        "                    bag_of_words=vec1.transform(corpus)\n",
        "                    sum_words= bag_of_words.sum(axis=0)\n",
        "                    words_freq=[(word,sum_words[0,idx])for word,idx in vec1.vocabulary_.items()]\n",
        "                    words_freq=sorted(words_freq,key=lambda x:x[1], reverse=True)\n",
        "                    return words_freq[:n]\n",
        "                #Bigram Plot\n",
        "                top2_words=get_top_n2_words(corpus,n=20)\n",
        "                top2_df=pd.DataFrame(top2_words)\n",
        "                top2_df.columns=[\"Bi-gram\",\"Freq\"]\n",
        "                print(top2_df)\n",
        "\n",
        "                sns.set(rc={'figure.figsize':(15,12)})\n",
        "                h=sns.barplot(x=\"Bi-gram\", y=\"Freq\", data=top2_df)\n",
        "                h.set_xticklabels(h.get_xticklabels(), rotation=45)\n",
        "                h.figure.savefig(dir+\"bigram.png\",dpi=1000)\n",
        "                \n",
        "                print(\"STARTING TRI GRAMS\")\n",
        "                #Tri-Grams\n",
        "                def get_top_n3_words(corpus,n=None):\n",
        "                    vec1=CountVectorizer(ngram_range=(3,3),max_features=2000).fit(corpus)\n",
        "                    bag_of_words=vec1.transform(corpus)\n",
        "                    sum_words= bag_of_words.sum(axis=0)\n",
        "                    words_freq=[(word,sum_words[0,idx]) for word, idx in vec1.vocabulary_.items()]\n",
        "                    words_freq=sorted(words_freq,key=lambda x:x[1],reverse=True)\n",
        "                    return words_freq[:n]\n",
        "                top3_words= get_top_n3_words(corpus, n=20)\n",
        "\n",
        "                top3_df=pd.DataFrame(top3_words)\n",
        "                top3_df.columns=[\"Tri-gram\",\"Freq\"]\n",
        "                print(top3_df)\n",
        "\n",
        "                sns.set(rc={'figure.figsize':(15,12)})\n",
        "                j=sns.barplot(x=\"Tri-gram\",y=\"Freq\",data=top3_df)\n",
        "                j.set_xticklabels(j.get_xticklabels(),rotation=45)\n",
        "                j.figure.savefig(dir+\"trigram.png\",dpi=1000)\n",
        "                \n",
        "                print(\"STARTING TI IDF\")\n",
        "                #Implementation of TF-IDF\n",
        "                tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
        "                tfidf_transformer.fit(X)\n",
        "                #get feature names\n",
        "                feature_names=cv.get_feature_names_out()\n",
        "                \n",
        "                #Ordino i risultati di tf-idf in base al punteggio\n",
        "                def sort_coo(coo_matrix):\n",
        "                    tuples= zip(coo_matrix.col, coo_matrix.data)\n",
        "                    return sorted(tuples,key=lambda x: (x[1],x[0]), reverse=True)\n",
        "                \n",
        "                def extract_topn_from_vector(feature_names,sorted_items,topn=10):\n",
        "                    \"get the feature names and tf-idf score of top n items\"\n",
        "                    sorted_items= sorted_items[:topn]\n",
        "                    score_vals=[]\n",
        "                    feature_vals=[]\n",
        "                    #Index name and results\n",
        "                    for idx,score in sorted_items:\n",
        "                        score_vals.append(round(score,3))\n",
        "                        feature_vals.append(feature_names[idx])\n",
        "                        results={}\n",
        "                        for idx in range(len(feature_vals)):\n",
        "                            results[feature_vals[idx]]=score_vals[idx]\n",
        "                    return results\n",
        "            \n",
        "            \n",
        "                #genera tf-idf per il documento\n",
        "                tf_idf_vector=tfidf_transformer.transform(cv.transform(corpus))\n",
        "                sorted_items=sort_coo(tf_idf_vector.tocoo())\n",
        "\n",
        "                #top n=10 items da restituire\n",
        "                keywords=extract_topn_from_vector(feature_names,sorted_items,10)\n",
        "\n",
        "                print(\"\\nKeywords:\")\n",
        "                fileresults.write(\"Keywords\\n\")\n",
        "                for k in keywords:\n",
        "                    print(k,keywords[k])\n",
        "                    fileresults.write(k+\" \"+ str(keywords[k])+\"\\n\")\n",
        "                fileresults.close()\n",
        "                \n",
        "            \n",
        "            \n",
        "            #FROM HERE WE END\n",
        "            except:\n",
        "                print(\"Cartella non creata\")       \n",
        "print(\"checking words\")\n",
        "print(\"files found:\")\n",
        "print(c)\n",
        "if(c==0):\n",
        "    print(\"No file found\")\n",
        "    quit()\n",
        "for i in files:\n",
        "    print(i[\"title\"])\n",
        "\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l0iTWfr1-2jn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}